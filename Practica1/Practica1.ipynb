{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1 - Aprendizaje automático\n",
    "### Grupo 1463\n",
    "---------\n",
    "\n",
    "* Pablo Marcos Manchón\n",
    "* Dionisio Pérez Alvear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos Librerias\n",
    "import numpy as np\n",
    "import collections\n",
    "from abc import ABCMeta,abstractmethod\n",
    "from scipy.stats import norm\n",
    "\n",
    "#from sklearn import datasets\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de la clase ***Datos*** implementada en la práctica 0.\n",
    "\n",
    "Hemos añadido unas pocas variaciones respecto al diseño original:\n",
    "* Al inicializar puede especificarse el tipo de datos con el que se guarda la matriz de datos (atributo cast).\n",
    "* Metodos _ _ len _ _ , _ _ getitem _ _ y _ _ yield_ _ sobrecargados para utilizar de forma mas cómoda la clase.\n",
    "* El método extraeDatos permite indexar por\n",
    "\n",
    "El resto de atributos y funciones se encuentran documentados en el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Datos(object):\n",
    "    \"\"\"Clase para leer y almacenar los datos de los ficheros .data proporcionados\n",
    "\n",
    "    Attributes:\n",
    "        ndatos (int): Numero de entradas de nuestro conjunto de datos\n",
    "        nAtributos (int): Numero de atributos de cada dato\n",
    "        nombreAtributos (list): Lista con los nombres de los atributos\n",
    "        tipoAtributos (list): Lista con string representando el tipo de cada atributo\n",
    "        nominalAtributos (list): Lista con True en las posiciones de los atributos nominales\n",
    "        diccionarios (list): Lista de diccionarios con el valor de cada uno de los atributos nominales\n",
    "        datos (numpy.ndarray) : Matrix ndatosxnAtributos con los datos recolectados y los atributos\n",
    "            nominales traducidos.\n",
    "    \"\"\"\n",
    "\n",
    "    TiposDeAtributos=('Continuo','Nominal')\n",
    "\n",
    "    def __init__(self, nombreFichero, cast=None):\n",
    "        \"\"\"Constructor de la clase Datos\n",
    "\n",
    "        Args:\n",
    "            nombreFichero (str): path del fichero de datos a cargar\n",
    "            cast (np.dtype, opcional) : Si se especifica la matriz de datos se\n",
    "                casteara al tipo especificado, en otro caso si todos los atributos\n",
    "                son nominales se almacenaran en tipo entero y si hay algun dato\n",
    "                continuo en tipo float.\n",
    "        \"\"\"\n",
    "\n",
    "        # Abrimos el fichero y procesamos la cabecera\n",
    "        with open(nombreFichero) as f:\n",
    "\n",
    "            # Guardamos el numero de datos\n",
    "            self.nDatos = int(f.readline())\n",
    "\n",
    "            # Guardamos la lista de nombres de atributos\n",
    "            self.nombreAtributos = f.readline().replace('\\n','').split(\",\")\n",
    "\n",
    "            # Guardamos la lista de atributos\n",
    "            self.tipoAtributos = f.readline().replace('\\n','').split(\",\")\n",
    "\n",
    "            # Numero de atributos\n",
    "            self.nAtributos = len(self.tipoAtributos)\n",
    "\n",
    "            # Comprobacion atributos\n",
    "            if any(atr not in Datos.TiposDeAtributos for atr in self.tipoAtributos):\n",
    "                raise ValueError(\"Tipo de atributo erroneo\")\n",
    "\n",
    "            # Guardamos True en las posiciones de atributos nominales\n",
    "            self.nominalAtributos = [atr == 'Nominal' for atr in self.tipoAtributos]\n",
    "\n",
    "        # Leemos los datos de numpy en formate string para los datos nominales\n",
    "        datosNominales = np.genfromtxt(nombreFichero, dtype='S', skip_header=3, delimiter=',')\n",
    "\n",
    "        # Inicializamos los diccionarios con los distintos valores de los atributos\n",
    "        self._inicializarDiccionarios(datosNominales)\n",
    "\n",
    "        # Transformamos los datos nominales en datos numericos empleando los diccionarios\n",
    "        for i, nominal in enumerate(self.nominalAtributos):\n",
    "            if nominal:\n",
    "                datosNominales[:,i] = np.vectorize(self.diccionarios[i].get)(datosNominales[:,i])\n",
    "\n",
    "        # Convertimos la matriz a tipo numerico, en caso de no especificarse\n",
    "        # Si todos los atributos son nominales usamos el tipo np.int para ahorrar espacio\n",
    "        # Si hay datos continuos lo guardamos en tipo np.float\n",
    "        if cast == None: cast = np.int if all(self.nominalAtributos) else np.float\n",
    "        self.datos = datosNominales.astype(cast)\n",
    "\n",
    "        # Convertimos los nombres nominales a string en vez de dejarlos en bytes\n",
    "        diccionarios_aux = []\n",
    "        for d in self.diccionarios:\n",
    "            aux = {}\n",
    "            for k in d: aux[k.decode('utf-8')] = d[k]\n",
    "            diccionarios_aux.append(aux)\n",
    "\n",
    "        self.diccionarios = diccionarios_aux\n",
    "\n",
    "    def _inicializarDiccionarios(self, datos):\n",
    "        \"\"\"Funcion interna para inicializar los diccionarios buscando todos\n",
    "            los valores que toman los atributos en la matriz de datos\"\"\"\n",
    "\n",
    "        self.diccionarios = []\n",
    "\n",
    "        for i, nominal in enumerate(self.nominalAtributos):\n",
    "\n",
    "            if not nominal: # Incluimos diccionarios vacios en los datos no nominales\n",
    "                self.diccionarios.append({})\n",
    "            else:\n",
    "                # Buscamos todos los valores distintos por atributo y creamos el diccionario\n",
    "                values = np.unique(datos[:,i])\n",
    "                values.sort()\n",
    "                self.diccionarios.append({k: v for v, k in enumerate(values)})\n",
    "\n",
    "    def extraeDatos(self, idx):\n",
    "        return self.datos[idx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.extraeDatos(idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.nDatos\n",
    "    \n",
    "    def __yield__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self.datos[i]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Particion:\n",
    "  \n",
    "    def __init__(self, train=[], test=[]):\n",
    "        self.indicesTrain= train\n",
    "        self.indicesTest= test\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Particion:\\nTrain: {}\\nTest:  {}\".format(str(self.indicesTrain),str(self.indicesTest)) \n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "class EstrategiaParticionado:\n",
    "  \n",
    "      # Clase abstracta\n",
    "    __metaclass__ = ABCMeta\n",
    "  \n",
    "    def __init__(self, nombre=\"null\"):\n",
    "        self.nombreEstrategia=nombre\n",
    "        self.numeroParticiones=0\n",
    "        self.particiones=[]\n",
    "    \n",
    "    def __call__(self, datos):\n",
    "        return self.creaParticiones(datos)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for part in self.particiones:\n",
    "            yield part\n",
    "  \n",
    "    @abstractmethod\n",
    "    # TODO: esta funcion deben ser implementadas en cada estrategia concreta  \n",
    "    def creaParticiones(self,datos,seed=None):\n",
    "        pass\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "class ValidacionSimple(EstrategiaParticionado):\n",
    "    \"\"\"Crea particiones segun el metodo tradicional \n",
    "    de division de los datos segun el porcentaje deseado.\"\"\"\n",
    "    \n",
    "    def __init__(self,porcentaje=.75):\n",
    "\n",
    "        self.porcentaje = porcentaje\n",
    "        super().__init__(\"Validacion Simple con {}\\% de entrenamiento\".format(100*porcentaje))\n",
    "\n",
    "\n",
    "    def creaParticiones(self,datos,seed=None):    \n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.numeroParticiones = 1\n",
    "\n",
    "        # Generamos una permutacion de los indices\n",
    "        indices = np.arange(datos.nDatos)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        # Separamos en base al porcentaje necesario\n",
    "        l = int(datos.nDatos*self.porcentaje)\n",
    "        self.particiones = [Particion(indices[:l], indices[l:])]\n",
    "\n",
    "        return self.particiones\n",
    "    \n",
    "      \n",
    "#####################################################################################################      \n",
    "class ValidacionCruzada(EstrategiaParticionado):\n",
    "    \n",
    "    def __init__(self, k=1):\n",
    "        self.k = k\n",
    "        super().__init__(\"Validacion Cruzada con {} particiones\".format(k))\n",
    "  \n",
    "  # Crea particiones segun el metodo de validacion cruzada.\n",
    "  # El conjunto de entrenamiento se crea con las nfolds-1 particiones\n",
    "  # y el de test con la particion restante\n",
    "  # Esta funcion devuelve una lista de particiones (clase Particion)\n",
    "    def creaParticiones(self,datos,seed=None):   \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        self.numeroParticiones = self.k\n",
    "        # Tam de cada bloque\n",
    "        l = int(datos.nDatos/self.k)\n",
    "        \n",
    "        # Generamos una permutacion de los indices\n",
    "        indices = np.arange(datos.nDatos)\n",
    "        np.random.shuffle(indices)\n",
    "        self.particiones = []\n",
    "        \n",
    "        \n",
    "        for i in range(self.k):\n",
    "\n",
    "            train = np.delete(indices, range(i*l,(i+1)*l))\n",
    "            test =  indices[i*l:(i+1)*l-1]\n",
    "            self.particiones.append(Particion(train, test))\n",
    "                                    \n",
    "        return self.particiones\n",
    "            \n",
    "        \n",
    "    \n",
    "#####################################################################################################\n",
    "\n",
    "class ValidacionBootstrap(EstrategiaParticionado):\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        super().__init__(\"Validacion Bootstrap con {} particiones\".format(n))\n",
    "        self.n = n\n",
    "\n",
    "  # Crea particiones segun el metodo de boostrap\n",
    "  # Devuelve una lista de particiones (clase Particion)\n",
    "    def creaParticiones(self,datos,seed=None):    \n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.numeroParticiones = self.n\n",
    "\n",
    "        # Generamos una permutacion de los indices\n",
    "        indices = np.arange(datos.nDatos)\n",
    "        self.particiones = []\n",
    "\n",
    "        for i in range(self.n):\n",
    "\n",
    "            # Generamos numeros aleatorios con repeticion\n",
    "            aleatorios = np.random.randint(0, datos.nDatos, datos.nDatos)\n",
    "            # Nos quedamos los ejemplos de los indices\n",
    "            train = indices[aleatorios]\n",
    "            # Obtenemos los indices que han sido excluidos\n",
    "            excluidos = [i not in aleatorios for i in indices] \n",
    "            \n",
    "            # El conjunto de indices esta formado por los indices excluidos\n",
    "            test = indices[excluidos]\n",
    "\n",
    "            self.particiones.append(Particion(train, test))\n",
    "\n",
    "        return self.particiones\n",
    "    \n",
    "#####################################################################################################\n",
    "\n",
    "    \n",
    "class ValidacionSimpleScikit(EstrategiaParticionado):\n",
    "    \"\"\"Crea particiones segun el metodo tradicional \n",
    "    de division de los datos segun el porcentaje deseado.\"\"\"\n",
    "    \n",
    "    def __init__(self,porcentaje=.75):\n",
    "\n",
    "        self.porcentaje = porcentaje\n",
    "        super().__init__(\"Validacion Simple Scikit con {}\\% de entrenamiento\".format(100*porcentaje))\n",
    "\n",
    "    def creaParticiones(self,datos,seed=None): \n",
    "        \n",
    "        #Primero encriptamos los atributos\n",
    "        encAtributos = preprocessing.OneHotEncoder(categorical_features=datos.nominalAtributos[:-1], sparse=False)\n",
    "        \n",
    "        # Guardamos la matriz de atributos codificada\n",
    "        X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "        # Guardamos la clase de cada patron\n",
    "        Y =dataset.datos[:,-1] \n",
    "\n",
    "        # Creamos Train y Test para atributos y clases (clases tb?)\n",
    "        XTrain, XTest = train_test_split(X, train_size = self.porcentaje, shuffle=True)\n",
    "        YTrain, YTest = train_test_split(Y, train_size = self.porcentaje, shuffle=True) #?\n",
    "        \n",
    "        self.particiones.append(Particion(XTrain, XTest))\n",
    "        self.particiones.append(Particion(YTrain, YTest))\n",
    "        \n",
    "        return self.particiones\n",
    "    \n",
    "#####################################################################################################\n",
    "\n",
    "    \n",
    "class ValidacionCruzadaScikit(EstrategiaParticionado):\n",
    "    \"\"\"Crea particiones segun el metodo tradicional \n",
    "    de division de los datos segun el porcentaje deseado.\"\"\"\n",
    "    \n",
    "    def __init__(self, k=1):\n",
    "        self.k = k\n",
    "        super().__init__(\"Validacion Cruzada Scikit con {} particiones\".format(k))\n",
    "\n",
    "    def creaParticiones(self,datos,seed=None): \n",
    "        \n",
    "        self.numeroParticiones = self.k\n",
    "        self.particiones = []\n",
    "            \n",
    "        #Primero encriptamos los atributos\n",
    "        encAtributos = preprocessing.OneHotEncoder(categorical_features=datos.nominalAtributos[:-1], sparse=False)\n",
    "        \n",
    "        # Guardamos la matriz de atributos codificada\n",
    "        X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "        # Guardamos la clase de cada patron\n",
    "        Y =dataset.datos[:,-1]    \n",
    "\n",
    "        # Creamos particiones\n",
    "        kf = KFold(n_splits=self.k, shuffle=True)\n",
    "        for train, test in kf.split(X, Y):\n",
    "            XTrain, XTest = X[train], X[test]\n",
    "            YTrain, YTest = Y[train], Y[test]\n",
    "            self.particiones.append(Particion(XTrain, XTest))\n",
    "            self.particiones.append(Particion(YTrain, YTest))\n",
    "        \n",
    "        return self.particiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de los metodos de particiones de la semana1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    dataset = Datos('../ConjuntosDatos/balloons.data')\n",
    "    \n",
    "    \n",
    "    # Creamos una particion con validacion simple\n",
    "    validacion1 = ValidacionSimple(0.8)\n",
    "    particion1 = validacion1(dataset)\n",
    "    \n",
    "    # Creamos una particion con validacion cruzada\n",
    "    k=4\n",
    "    validacion2 = ValidacionCruzada(k)\n",
    "    particion2 = validacion2(dataset)\n",
    "    \n",
    "    # Creamos una particion usando Validacion Bootstrap\n",
    "    n=10\n",
    "    validacion3 = ValidacionBootstrap(n)\n",
    "    particion3 = validacion3(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Clasificador:\n",
    "  \n",
    "    # Clase abstracta\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    # Metodos abstractos que se implementan en casa clasificador concreto\n",
    "    @abstractmethod\n",
    "    # TODO: esta funcion deben ser implementadas en cada clasificador concreto\n",
    "    # datosTrain: matriz numpy con los datos de entrenamiento\n",
    "    # atributosDiscretos: array bool con la indicatriz de los atributos nominales\n",
    "    # diccionario: array de diccionarios de la estructura Datos utilizados para la codificacion\n",
    "    # de variables discretas\n",
    "    def entrenamiento(self,datosTrain,atributosDiscretos,diccionario):\n",
    "        pass\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    # TODO: esta funcion deben ser implementadas en cada clasificador concreto\n",
    "    # devuelve un numpy array con las predicciones\n",
    "    def clasifica(self,datosTest,atributosDiscretos,diccionario):\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Obtiene el numero de aciertos y errores para calcular la tasa de fallo\n",
    "    # TODO: implementar\n",
    "    def error(self,datos,pred):\n",
    "    # Aqui se compara la prediccion (pred) con las clases reales y se calcula el error    \n",
    "        pass\n",
    "\n",
    "\n",
    "    # Realiza una clasificacion utilizando una estrategia de particionado determinada\n",
    "    # TODO: implementar esta funcion\n",
    "    def validacion(self,particionado,dataset,clasificador,seed=None):\n",
    "\n",
    "    # Creamos las particiones siguiendo la estrategia llamando a particionado.creaParticiones\n",
    "    # - Para validacion cruzada: en el bucle hasta nv entrenamos el clasificador con la particion de train i\n",
    "    # y obtenemos el error en la particion de test i\n",
    "    # - Para validacion simple (hold-out): entrenamos el clasificador con la particion de train\n",
    "    # y obtenemos el error en la particion test\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ScikitNaiveBayes(Clasificador):\n",
    "    \n",
    "    def entrenamiento(self, datos, indices):\n",
    "          \n",
    "        # Calculamos las posteriori de los discretos\n",
    "        self.NB = nb.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "        # Calculamos NaiveBayes\n",
    "        self.NB.fit(indices[0], indices[1])\n",
    "        # indices[0] contiene la particion de datos\n",
    "        # indices[1] contiene la particion de clases (?) \n",
    "        # y en el caso de val.cruzada?\n",
    "\n",
    "    def clasifica(self, datos, indices):\n",
    "        \n",
    "        print(self.NB.predict(indices[0]))     \n",
    "                \n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ClasificadorNaiveBayes(Clasificador):\n",
    "\n",
    "\n",
    "    def entrenamiento(self, datos, indices, laplace=False): \n",
    "\n",
    "        # Numero de atributos\n",
    "        self.nAtributos = len(datos.diccionarios) - 1\n",
    "  \n",
    "        # Numero de clases (longitud del diccionario del campo clase)\n",
    "        self.nClases = len(datos.diccionarios[-1])\n",
    "        \n",
    "        # Normalizacion de laplace\n",
    "        self.laplace = laplace\n",
    "        \n",
    "        # Guardamos que atributos son nominales\n",
    "        self.nominalAtributos = datos.nominalAtributos\n",
    "        \n",
    "        # Variables necesarias para el entrenamiento\n",
    "        # (No se guaran en la estructura)\n",
    "        nEntrenamiento = len(indices)\n",
    "        datosEntrenamiento = datos[indices]\n",
    "        arrayClases = datosEntrenamiento[:,-1]\n",
    "\n",
    "        # Tablas de probabilidad a priori (una por clase)\n",
    "        self.priori = self._calcula_prioris(arrayClases)\n",
    "        \n",
    "        \n",
    "        # Tablas de probabilidad a posteriori (una por atributo)\n",
    "        self.posteriori = np.empty(self.nAtributos, dtype=object)\n",
    "               \n",
    "        # Iteramos sobre los datos de entrenamiento (sin contar la clase)\n",
    "        for i, discreto in enumerate(datos.nominalAtributos[:-1]):\n",
    "            \n",
    "            # Caso atributo discreto\n",
    "            if discreto:\n",
    "                # Numero de valores que toma el atributo\n",
    "                n_valores = len(datos.diccionarios[i])\n",
    "                \n",
    "                # Creamos la tabla de probabilidades a posteriori donde\n",
    "                # el elemento (i,j) guardara P(C_i | X=j)\n",
    "                self.posteriori[i] = self._entrena_discreto(datosEntrenamiento[:,i], \n",
    "                                                            arrayClases, \n",
    "                                                            n_valores)\n",
    "                \n",
    "            else:\n",
    "               # Creamos una tabla que guardara la media y desviacion del dato\n",
    "                self.posteriori[i] = self._entrena_continuo(datosEntrenamiento[:,i], \n",
    "                                                            arrayClases)              \n",
    "\n",
    "                \n",
    "    def _calcula_prioris(self, clases):\n",
    "        r\"\"\"Calcula la tabla de probabilidades a priori\n",
    "        \n",
    "            Args:\n",
    "                clases: array con clases\n",
    "            Returns:\n",
    "                array con probabilidades a posteriori\n",
    "        \"\"\"\n",
    "        \n",
    "        # Lista para prioris\n",
    "        prioris = np.empty(self.nClases)\n",
    "        n_entrenamiento = len(clases)\n",
    "        \n",
    "        # Calcuamos las probabilidades a priori\n",
    "        for c in range(self.nClases):\n",
    "            prioris[c] = len(np.where(clases == c)[0])/ n_entrenamiento\n",
    "        \n",
    "        \n",
    "        return prioris\n",
    "        \n",
    "    def _entrena_discreto(self, datos, clases, n_valores):\n",
    "        r\"\"\"Funcion para calcular la tabla de probabilidad a \n",
    "        posteriori de un atributo\n",
    "        \n",
    "        Args: \n",
    "            datos: Array unidimensional con valores del atributo\n",
    "            clases: Array con valores de la clase para cada atributo\n",
    "            n_valores: Numero de valores que puede tomar el atributo\n",
    "        \n",
    "        Returns:\n",
    "            numpy.array con la tabla de probabilidades a posteriori\n",
    "        \"\"\"\n",
    "        \n",
    "        # Tabla de probabilidades a posteriori\n",
    "        posteriori = np.zeros((self.nClases, n_valores))\n",
    "        \n",
    "        # Calculamos los conteos de atributos de cada clase      \n",
    "        for c in range(self.nClases):\n",
    "            \n",
    "            # Repeticiones de la clase c por valor\n",
    "            repeticiones = collections.Counter(datos[clases == c])\n",
    "\n",
    "            for v in repeticiones:\n",
    "                posteriori[c,int(v)] = repeticiones[v]\n",
    "\n",
    "            \n",
    "        # Comprueba si hay que hacer correccion de laplace\n",
    "        if self.laplace and (posteriori == 0).any():\n",
    "            posteriori += 1\n",
    "            n_valores += 1\n",
    "            \n",
    "        # Dividimos entre el numero de datos para obtener las probabilidades\n",
    "        posteriori /= len(clases)\n",
    "                \n",
    "        return posteriori\n",
    "                \n",
    "    def _entrena_continuo(self, datos, clases):\n",
    "        r\"\"\"Funcion para calcular los datos de un atributo\n",
    "            continuo, guardara para cada una de las clases\n",
    "            su media y desviacion estandart\n",
    "        \"\"\"\n",
    "        # Tabla con los datos para cada una de las clases\n",
    "        estadisticas = np.empty((self.nClases, 2))\n",
    "        \n",
    "        for c in range(self.nClases):\n",
    "            data = datos[clases == c]\n",
    "            estadisticas[c,0] = np.mean(data)\n",
    "            estadisticas[c,1] = np.std(data)\n",
    "            \n",
    "        return estadisticas\n",
    "            \n",
    "    def probabilidadClase(self, dato):\n",
    "\n",
    "        # Inicializamos la lista con las probabilidades a priori\n",
    "        probabilidades = np.copy(self.priori)\n",
    "        \n",
    "        for c in range(self.nClases):\n",
    "            for atr, nominal in enumerate(self.nominalAtributos[:-1]): \n",
    "                if nominal:\n",
    "                    # Atributo discreto\n",
    "                    probabilidades[c] *= self.posteriori[atr][c, int(dato[atr])]\n",
    "                else:\n",
    "                    # Atributo continuo\n",
    "                    probabilidades[c] *= norm.pdf(dato[atr], \n",
    "                                                  self.posteriori[atr][c, 0], \n",
    "                                                  self.gaussianas[atr][c, 1])\n",
    "            \n",
    "        # Normalizamos las probabilidades\n",
    "        probabilidades /= np.sum(probabilidades)\n",
    "            \n",
    "        return probabilidades\n",
    "\n",
    "            \n",
    "\n",
    "    def clasifica(self, datos, indices):\n",
    "        r\"\"\" Clasifica los datos una vez entrenado el clasificador\n",
    "            Args:\n",
    "                datos: Clase Datos con los datos cargados\n",
    "                indices: Lista con indices de datos a clasificar\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        clasificacion = np.full(len(indices), -1)\n",
    "        \n",
    "        for i, dato in enumerate(datos[indices]):\n",
    "                \n",
    "            probabilidades = self.probabilidadClase(dato)\n",
    "            clasificacion[i] = np.argmax(probabilidades)\n",
    "\n",
    "             \n",
    "        return clasificacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos('../ConjuntosDatos/balloons.data')\n",
    "\n",
    "# Creamos particion\n",
    "#validacion1 = ValidacionSimple(0.8)\n",
    "#particion1 = validacion1(dataset)\n",
    "\n",
    "# Creamos clasificador Naive-Bayes\n",
    "c = ClasificadorNaiveBayes()\n",
    "c.entrenamiento(dataset, range(20),False)\n",
    "clasificacion = c.clasifica(dataset, range(20))\n",
    "#print(dataset[particion1[0].indicesTest])\n",
    "#clasificacion = c.clasifica(dataset, range(len(dataset)))\n",
    "\n",
    "# Particion por validacion simple scikit\n",
    "#validacion1 = ValidacionSimpleScikit(0.8)\n",
    "#particion1 = validacion1(dataset)\n",
    "#Particion por validacion cruzada scikit\n",
    "#validacion2 = ValidacionCruzadaScikit(4)\n",
    "#particion2 = validacion2(dataset)\n",
    "\n",
    "#c = ScikitNaiveBayes()\n",
    "#c.entrenamiento(dataset, [particion2[0].indicesTrain, particion2[1].indicesTrain])\n",
    "#c.clasifica(dataset, [particion2[0].indicesTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0]\n",
      "[1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.datos[:,-1])\n",
    "print(clasificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.datos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45762712, 0.54237288])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.probabilidadClase([1,1,1,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
