{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Pablo Marcos y Dionisio Perez\n",
    "\n",
    "# Importamos Librerias\n",
    "import numpy as np\n",
    "import collections\n",
    "from abc import ABCMeta,abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Datos(object):\n",
    "    \"\"\"Clase para leer y almacenar los datos de los ficheros .data proporcionados\n",
    "\n",
    "    Attributes:\n",
    "        ndatos (int): Numero de entradas de nuestro conjunto de datos\n",
    "        nAtributos (int): Numero de atributos de cada dato\n",
    "        nombreAtributos (list): Lista con los nombres de los atributos\n",
    "        tipoAtributos (list): Lista con string representando el tipo de cada atributo\n",
    "        nominalAtributos (list): Lista con True en las posiciones de los atributos nominales\n",
    "        diccionarios (list): Lista de diccionarios con el valor de cada uno de los atributos nominales\n",
    "        datos (numpy.ndarray) : Matrix ndatosxnAtributos con los datos recolectados y los atributos\n",
    "            nominales traducidos.\n",
    "    \"\"\"\n",
    "\n",
    "    TiposDeAtributos=('Continuo','Nominal')\n",
    "\n",
    "    def __init__(self, nombreFichero, cast=None):\n",
    "        \"\"\"Constructor de la clase Datos\n",
    "\n",
    "        Args:\n",
    "            nombreFichero (str): path del fichero de datos a cargar\n",
    "            cast (np.dtype, opcional) : Si se especifica la matriz de datos se\n",
    "                casteara al tipo especificado, en otro caso si todos los atributos\n",
    "                son nominales se almacenaran en tipo entero y si hay algun dato\n",
    "                continuo en tipo float.\n",
    "        \"\"\"\n",
    "\n",
    "        # Abrimos el fichero y procesamos la cabecera\n",
    "        with open(nombreFichero) as f:\n",
    "\n",
    "            # Guardamos el numero de datos\n",
    "            self.nDatos = int(f.readline())\n",
    "\n",
    "            # Guardamos la lista de nombres de atributos\n",
    "            self.nombreAtributos = f.readline().replace('\\n','').split(\",\")\n",
    "\n",
    "            # Guardamos la lista de atributos\n",
    "            self.tipoAtributos = f.readline().replace('\\n','').split(\",\")\n",
    "\n",
    "            # Numero de atributos\n",
    "            self.nAtributos = len(self.tipoAtributos)\n",
    "\n",
    "            # Comprobacion atributos\n",
    "            if any(atr not in Datos.TiposDeAtributos for atr in self.tipoAtributos):\n",
    "                raise ValueError(\"Tipo de atributo erroneo\")\n",
    "\n",
    "            # Guardamos True en las posiciones de atributos nominales\n",
    "            self.nominalAtributos = [atr == 'Nominal' for atr in self.tipoAtributos]\n",
    "\n",
    "        # Leemos los datos de numpy en formate string para los datos nominales\n",
    "        datosNominales = np.genfromtxt(nombreFichero, dtype='S', skip_header=3, delimiter=',')\n",
    "\n",
    "        # Inicializamos los diccionarios con los distintos valores de los atributos\n",
    "        self._inicializarDiccionarios(datosNominales)\n",
    "\n",
    "        # Transformamos los datos nominales en datos numericos empleando los diccionarios\n",
    "        for i, nominal in enumerate(self.nominalAtributos):\n",
    "            if nominal:\n",
    "                datosNominales[:,i] = np.vectorize(self.diccionarios[i].get)(datosNominales[:,i])\n",
    "\n",
    "        # Convertimos la matriz a tipo numerico, en caso de no especificarse\n",
    "        # Si todos los atributos son nominales usamos el tipo np.int para ahorrar espacio\n",
    "        # Si hay datos continuos lo guardamos en tipo np.float\n",
    "        if cast == None: cast = np.int if all(self.nominalAtributos) else np.float\n",
    "        self.datos = datosNominales.astype(cast)\n",
    "\n",
    "        # Convertimos los nombres nominales a string en vez de dejarlos en bytes\n",
    "        diccionarios_aux = []\n",
    "        for d in self.diccionarios:\n",
    "            aux = {}\n",
    "            for k in d: aux[k.decode('utf-8')] = d[k]\n",
    "            diccionarios_aux.append(aux)\n",
    "\n",
    "        self.diccionarios = diccionarios_aux\n",
    "\n",
    "    def _inicializarDiccionarios(self, datos):\n",
    "        \"\"\"Funcion interna para inicializar los diccionarios buscando todos\n",
    "            los valores que toman los atributos en la matriz de datos\"\"\"\n",
    "\n",
    "        self.diccionarios = []\n",
    "\n",
    "        for i, nominal in enumerate(self.nominalAtributos):\n",
    "\n",
    "            if not nominal: # Incluimos diccionarios vacios en los datos no nominales\n",
    "                self.diccionarios.append({})\n",
    "            else:\n",
    "                # Buscamos todos los valores distintos por atributo y creamos el diccionario\n",
    "                values = np.unique(datos[:,i])\n",
    "                values.sort()\n",
    "                self.diccionarios.append({k: v for v, k in enumerate(values)})\n",
    "\n",
    "    def extraeDatos(self, idx):\n",
    "        return self.datos[idx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.extraeDatos(idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.nDatos\n",
    "    \n",
    "    def __yield__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self.datos[i]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta,abstractmethod\n",
    "\n",
    "\n",
    "class Particion:\n",
    "  \n",
    "    def __init__(self, train=[], test=[]):\n",
    "        self.indicesTrain= train\n",
    "        self.indicesTest= test\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Particion:\\nTrain: {}\\nTest:  {}\".format(str(self.indicesTrain),str(self.indicesTest)) \n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "class EstrategiaParticionado:\n",
    "  \n",
    "      # Clase abstracta\n",
    "    __metaclass__ = ABCMeta\n",
    "  \n",
    "    def __init__(self, nombre=\"null\"):\n",
    "        self.nombreEstrategia=nombre\n",
    "        self.numeroParticiones=0\n",
    "        self.particiones=[]\n",
    "    \n",
    "    def __call__(self, datos):\n",
    "        return self.creaParticiones(datos)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for part in self.particiones:\n",
    "            yield part\n",
    "  \n",
    "    @abstractmethod\n",
    "    # TODO: esta funcion deben ser implementadas en cada estrategia concreta  \n",
    "    def creaParticiones(self,datos,seed=None):\n",
    "        pass\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "class ValidacionSimple(EstrategiaParticionado):\n",
    "    \"\"\"Crea particiones segun el metodo tradicional \n",
    "    de division de los datos segun el porcentaje deseado.\"\"\"\n",
    "    \n",
    "    def __init__(self,porcentaje=.75):\n",
    "\n",
    "        self.porcentaje = porcentaje\n",
    "        super().__init__(\"Validacion Simple con {}\\% de entrenamiento\".format(100*porcentaje))\n",
    "\n",
    "\n",
    "    def creaParticiones(self,datos,seed=None):    \n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.numeroParticiones = 1\n",
    "\n",
    "        # Generamos una permutacion de los indices\n",
    "        indices = np.arange(datos.nDatos)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        # Separamos en base al porcentaje necesario\n",
    "        l = int(datos.nDatos*self.porcentaje)\n",
    "        self.particiones = [Particion(indices[:l], indices[l:])]\n",
    "\n",
    "        return self.particiones\n",
    "    \n",
    "      \n",
    "#####################################################################################################      \n",
    "class ValidacionCruzada(EstrategiaParticionado):\n",
    "    \n",
    "    def __init__(self, k=1):\n",
    "        self.k = k\n",
    "        super().__init__(\"Validacion Cruzada con {} particiones\".format(k))\n",
    "  \n",
    "  # Crea particiones segun el metodo de validacion cruzada.\n",
    "  # El conjunto de entrenamiento se crea con las nfolds-1 particiones\n",
    "  # y el de test con la particion restante\n",
    "  # Esta funcion devuelve una lista de particiones (clase Particion)\n",
    "    def creaParticiones(self,datos,seed=None):   \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        self.numeroParticiones = self.k\n",
    "        # Tam de cada bloque\n",
    "        l = int(datos.nDatos/self.k)\n",
    "        \n",
    "        # Generamos una permutacion de los indices\n",
    "        indices = np.arange(datos.nDatos)\n",
    "        np.random.shuffle(indices)\n",
    "        self.particiones = []\n",
    "        \n",
    "        \n",
    "        for i in range(self.k):\n",
    "\n",
    "            train = np.delete(indices, range(i*l,(i+1)*l))\n",
    "            test =  indices[i*l:(i+1)*l-1]\n",
    "            self.particiones.append(Particion(train, test))\n",
    "                                    \n",
    "        return self.particiones\n",
    "            \n",
    "        \n",
    "    \n",
    "#####################################################################################################\n",
    "\n",
    "class ValidacionBootstrap(EstrategiaParticionado):\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        super().__init__(\"Validacion Bootstrap con {} particiones\".format(n))\n",
    "        self.n = n\n",
    "\n",
    "  # Crea particiones segun el metodo de boostrap\n",
    "  # Devuelve una lista de particiones (clase Particion)\n",
    "    def creaParticiones(self,datos,seed=None):    \n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.numeroParticiones = self.n\n",
    "\n",
    "        # Generamos una permutacion de los indices\n",
    "        indices = np.arange(datos.nDatos)\n",
    "        self.particiones = []\n",
    "\n",
    "        for i in range(self.n):\n",
    "\n",
    "            # Generamos numeros aleatorios con repeticion\n",
    "            aleatorios = np.random.randint(0, datos.nDatos, datos.nDatos)\n",
    "            # Nos quedamos los ejemplos de los indices\n",
    "            train = indices[aleatorios]\n",
    "            # Obtenemos los indices que han sido excluidos\n",
    "            excluidos = [i not in aleatorios for i in indices] \n",
    "            \n",
    "            # El conjunto de indices esta formado por los indices excluidos\n",
    "            test = indices[excluidos]\n",
    "\n",
    "            self.particiones.append(Particion(train, test))\n",
    "\n",
    "        return self.particiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prueba de los metodos de particiones de la semana1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    dataset = Datos('../ConjuntosDatos/balloons.data')\n",
    "    \n",
    "    \n",
    "    # Creamos una particion con validacion simple\n",
    "    validacion1 = ValidacionSimple(0.8)\n",
    "    particion1 = validacion1(dataset)\n",
    "    \n",
    "    # Creamos una particion con validacion cruzada\n",
    "    k=4\n",
    "    validacion2 = ValidacionCruzada(k)\n",
    "    particion2 = validacion2(dataset)\n",
    "    \n",
    "    # Creamos una particion usando Validacion Bootstrap\n",
    "    n=10\n",
    "    validacion3 = ValidacionBootstrap(n)\n",
    "    particion3 = validacion3(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Clasificador:\n",
    "  \n",
    "    # Clase abstracta\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    # Metodos abstractos que se implementan en casa clasificador concreto\n",
    "    @abstractmethod\n",
    "    # TODO: esta funcion deben ser implementadas en cada clasificador concreto\n",
    "    # datosTrain: matriz numpy con los datos de entrenamiento\n",
    "    # atributosDiscretos: array bool con la indicatriz de los atributos nominales\n",
    "    # diccionario: array de diccionarios de la estructura Datos utilizados para la codificacion\n",
    "    # de variables discretas\n",
    "    def entrenamiento(self,datosTrain,atributosDiscretos,diccionario):\n",
    "        pass\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    # TODO: esta funcion deben ser implementadas en cada clasificador concreto\n",
    "    # devuelve un numpy array con las predicciones\n",
    "    def clasifica(self,datosTest,atributosDiscretos,diccionario):\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Obtiene el numero de aciertos y errores para calcular la tasa de fallo\n",
    "    # TODO: implementar\n",
    "    def error(self,datos,pred):\n",
    "    # Aqui se compara la prediccion (pred) con las clases reales y se calcula el error    \n",
    "        pass\n",
    "\n",
    "\n",
    "    # Realiza una clasificacion utilizando una estrategia de particionado determinada\n",
    "    # TODO: implementar esta funcion\n",
    "    def validacion(self,particionado,dataset,clasificador,seed=None):\n",
    "\n",
    "    # Creamos las particiones siguiendo la estrategia llamando a particionado.creaParticiones\n",
    "    # - Para validacion cruzada: en el bucle hasta nv entrenamos el clasificador con la particion de train i\n",
    "    # y obtenemos el error en la particion de test i\n",
    "    # - Para validacion simple (hold-out): entrenamos el clasificador con la particion de train\n",
    "    # y obtenemos el error en la particion test\n",
    "        pass\n",
    "\n",
    "\n",
    "    ##############################################################################\n",
    "\n",
    "class ClasificadorNaiveBayes(Clasificador):\n",
    "\n",
    "\n",
    "    def entrenamiento(self, datos, indices): \n",
    "\n",
    "        # Numero de atributos discretos\n",
    "        self.nAtributosDiscretos = sum(datos.nominalAtributos) - 1\n",
    "        self.nAtributosContinuos = len(datos.diccionarios) - self.nAtributosDiscretos -1 \n",
    "        \n",
    "        \n",
    "        # Numero de clases (longitud del diccionario del campo clase)\n",
    "        self.nClases = len(datos.diccionarios[-1])\n",
    "        \n",
    "        # Maximo tam de posibles valores de atributos nominales\n",
    "        self.vAtributos = max([len(d) for d in datos.diccionarios[:-1]])\n",
    "        \n",
    "        # Tablas de probabilidad a posteriori\n",
    "        \n",
    "        self.posteriori = np.zeros((self.nAtributosDiscretos,self.vAtributos, self.nClases))\n",
    "        self.gaussianas =  np.zeros((self.nAtributosContinuos,self.nClases, 2))\n",
    "        # Mapeo entre indices reales y los indices de nuestras tablas\n",
    "        self.indicesDiscretos = {}\n",
    "        self.indicesContinuos = {}\n",
    "        d_index = 0 # Cuenta de indices empleados discretos\n",
    "        c_index = 0 # y continuos\n",
    "        \n",
    "        # Iteramos sobre los datos de entrenamiento (sin contar la clase)\n",
    "        for k, discreto in enumerate(datos.nominalAtributos[:-1]):\n",
    "            if discreto:\n",
    "                self.indicesDiscretos[k] = d_index\n",
    "                self._entrena_discreto(d_index, datos[:,k], datos[:,-1], datos.diccionarios[k], datos.nDatos)\n",
    "                d_index += 1\n",
    "            else:\n",
    "                self.indicesContinuos[k] = c_index\n",
    "                 self._entrena_continuo(c_index, datos[:,k], datos[:,-1])\n",
    "                \n",
    "                c_index += 1\n",
    "\n",
    "                \n",
    "    def _entrena_discreto(self, k, datos, clase, diccionario, n):\n",
    "        \n",
    "        # Calculamos los conteos de atributos de cada clase\n",
    "        repeticiones = np.empty(self.nClases, dtype=object)\n",
    "        for c in range(self.nClases):\n",
    "            repeticiones[c] = collections.Counter(datos[clase == c])\n",
    "\n",
    "            \n",
    "        # Correccion de laplace\n",
    "        laplace = any(np.array([len(r) for r in repeticiones]) != len(diccionario))\n",
    "        l= 1 if laplace else 0\n",
    "        \n",
    "        for c in range(self.nClases):\n",
    "            for v in diccionario:\n",
    "                atr = diccionario[v]\n",
    "                self.posteriori[k][atr][c] = (l + repeticiones[c][atr]) / (n+l)\n",
    "                \n",
    "    def _entrena_continuo(self, k, datos, clase):\n",
    "        \n",
    "        for c in range(self.nClases):\n",
    "            data = datos[clase == c]\n",
    "            self.gaussianas[k,c] np.mean(data)\n",
    "            sd = np.std(data)\n",
    "            \n",
    "\n",
    "    # TODO: implementar\n",
    "    def clasifica(self,datostest,atributosDiscretos,diccionario):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 7\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-c22bb6e0c5e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClasificadorNaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentrenamiento\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-69fe2dd021cf>\u001b[0m in \u001b[0;36mentrenamiento\u001b[0;34m(self, datos, indices)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindicesContinuos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mc_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_entrena_discreto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiccionario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = Datos('../ConjuntosDatos/german.data')\n",
    "\n",
    "\n",
    "c = ClasificadorNaiveBayes()\n",
    "c.entrenamiento(dataset, range(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.3         0.2       ]\n",
      "  [ 0.3         0.2       ]]\n",
      "\n",
      " [[ 0.3         0.2       ]\n",
      "  [ 0.3         0.2       ]]\n",
      "\n",
      " [[ 0.42857143  0.04761905]\n",
      "  [ 0.23809524  0.42857143]]\n",
      "\n",
      " [[ 0.23809524  0.42857143]\n",
      "  [ 0.42857143  0.04761905]]]\n"
     ]
    }
   ],
   "source": [
    "print(c.posteriori)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
